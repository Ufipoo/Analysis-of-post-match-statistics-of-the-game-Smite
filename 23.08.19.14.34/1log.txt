checkpoint = torch.load('D:/model_param/22.08.19.18.53/itr_160000')
model.load_state_dict(checkpoint['model_state_dict'])

optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
print("Optimizer's state_dict:")
for var_name in optimizer.state_dict():
    print(var_name, "\t", optimizer.state_dict()[var_name])
update_lr(optimizer, 0.001)
model.train()